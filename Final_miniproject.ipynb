{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gugan0306/NeuralStyleTransfer/blob/main/Final_miniproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-KXRY5XBu2u"
      },
      "outputs": [],
      "source": [
        "# @title Import libraries  { display-mode: \"form\" }\n",
        "import functools\n",
        "import os\n",
        "\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "print(\"TF Version: \", tf.__version__)\n",
        "print(\"TF Hub version: \", hub.__version__)\n",
        "print(\"Eager mode enabled: \", tf.executing_eagerly())\n",
        "print(\"GPU available: \", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tsoDv_9geoZn"
      },
      "outputs": [],
      "source": [
        "# @title Define image Structure  { display-mode: \"form\" }\n",
        "\n",
        "def crop_center(image):\n",
        "  \"\"\"Returns a cropped square image.\"\"\"\n",
        "  shape = image.shape\n",
        "  new_shape = min(shape[1], shape[2])\n",
        "  offset_y = max(shape[1] - shape[2], 0) // 2\n",
        "  offset_x = max(shape[2] - shape[1], 0) // 2\n",
        "  image = tf.image.crop_to_bounding_box(\n",
        "      image, offset_y, offset_x, new_shape, new_shape)\n",
        "  return image\n",
        "\n",
        "@functools.lru_cache(maxsize=None)\n",
        "def load_image(image_url, image_size=(256, 256), preserve_aspect_ratio=True):\n",
        "  \"\"\"Loads and preprocesses images.\"\"\"\n",
        "  # Cache image file locally.\n",
        "  image_path = tf.keras.utils.get_file(os.path.basename(image_url)[-128:], image_url)\n",
        "  # Load and convert to float32 numpy array, add batch dimension, and normalize to range [0, 1].\n",
        "  img = tf.io.decode_image(\n",
        "      tf.io.read_file(image_path),\n",
        "      channels=3, dtype=tf.float32)[tf.newaxis, ...]\n",
        "  img = crop_center(img)\n",
        "  img = tf.image.resize(img, image_size, preserve_aspect_ratio=True)\n",
        "  return img\n",
        "\n",
        "def show_n(images, titles=('',)):\n",
        "  n = len(images)\n",
        "  image_sizes = [image.shape[1] for image in images]\n",
        "  w = (image_sizes[0] * 6) // 320\n",
        "  plt.figure(figsize=(w * n, w))\n",
        "  gs = gridspec.GridSpec(1, n, width_ratios=image_sizes)\n",
        "  for i in range(n):\n",
        "    plt.subplot(gs[i])\n",
        "    plt.imshow(images[i][0], aspect='equal')\n",
        "    plt.axis('off')\n",
        "    plt.title(titles[i] if len(titles) > i else '')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRc0vat3Alzo"
      },
      "outputs": [],
      "source": [
        "# @title Load example images  { display-mode: \"form\" }\n",
        "\n",
        "content_image_url = \"https://m.timesofindia.com/thumb/msid-19214781,width-1200,height-900,resizemode-4/.jpg\" #@param [\"https://e7.pngegg.com/pngimages/114/521/png-clipart-mahatma-gandhi-non-cooperation-movement-my-life-india-gandhi-jayanti-india-thumbnail.png\", \"https://m.timesofindia.com/thumb/msid-19214781,width-1200,height-900,resizemode-4/.jpg\", \"\"] {allow-input: true}\n",
        "style_image_url = 'https://upload.wikimedia.org/wikipedia/commons/0/0a/The_Great_Wave_off_Kanagawa.jpg'  # @param {type:\"string\"}\n",
        "output_image_size = 384  # @param {type:\"integer\"}\n",
        "\n",
        "# The content image size can be arbitrary.\n",
        "content_img_size = (output_image_size, output_image_size)\n",
        "# The style prediction model was trained with image size 256 and it's the\n",
        "# recommended image size for the style image (though, other sizes work as\n",
        "# well but will lead to different results).\n",
        "style_img_size = (256, 256)  # Recommended to keep it at 256.\n",
        "\n",
        "content_image = load_image(content_image_url, content_img_size)\n",
        "style_image = load_image(style_image_url, style_img_size)\n",
        "style_image = tf.nn.avg_pool(style_image, ksize=[3,3], strides=[1,1], padding='SAME')\n",
        "show_n([content_image, style_image], ['Content image', 'Style image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnAv-F3O9fLV"
      },
      "outputs": [],
      "source": [
        "# @title  Actual stylization{ display-mode: \"form\" }\n",
        "# Stylize content image with given style image.\n",
        "# This is pretty fast within a few milliseconds on a GPU.\n",
        "# Load TF Hub module.\n",
        "\n",
        "hub_handle = 'https://tfhub.dev/google/magenta/arbitrary-image-stylization-v1-256/2'\n",
        "hub_module = hub.load(hub_handle)\n",
        "\n",
        "outputs = hub_module(tf.constant(content_image), tf.constant(style_image))\n",
        "stylized_image = outputs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEAPEdq698gs"
      },
      "outputs": [],
      "source": [
        "# @title Display input and output image{ display-mode: \"form\" }\n",
        "# Visualize input images and the generated stylized image.\n",
        "\n",
        "show_n([content_image, style_image, stylized_image], titles=['Original content image', 'Style image', 'Stylized image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4S3yg2MgkmRD"
      },
      "outputs": [],
      "source": [
        "# @title Blending ratio{ display-mode: \"form\" }\n",
        "# Define content blending ratio between [0..1].\n",
        "# 0.0: 0% style extracts from content image.\n",
        "# 1.0: 100% style extracted from content image.\n",
        "content_blending_ratio = 0.35#@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# Blend the style bottleneck of style image and content image\n",
        "style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \\\n",
        "                           + (1 - content_blending_ratio) * style_bottleneck\n",
        "\n",
        "# Stylize the content image using the style bottleneck.\n",
        "stylized_image_blended = run_style_transform(style_bottleneck_blended,\n",
        "                                             preprocessed_content_image)\n",
        "\n",
        "# Visualize the output.\n",
        "imshow(stylized_image_blended, 'Blended Stylized Image')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}